---
title: "Homework 2"
author: Lunbei Hu
output: github_document
---

This is my solution to HW2.

```{r setup}
library(tidyverse)
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

```{r}
trashwheel_df =
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data! for 2018 and 2017.

```{r}
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

```{r}
month_df =
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df =
  bind_rows(precip_2018, precip_2017)

precip_df =
  left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data. In this dataset:

* The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.


## Problem 2

Read the NY Transit dataset.

```{r}
subway_df = 
    read_csv(
      "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
    janitor::clean_names() %>% 
    select(line:entry, vending, ada) %>%
    mutate(
      entry = case_when(entry == "YES" ~ "TRUE", entry == "NO" ~ "FALSE"),
      entry = as.logical(entry)
    )
```

This dataset comes from NY Transit, with information on line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. 

To clean the data, I first recoded the variable names into snake case, and then converted the entry variable from character (YES vs NO) to a logical variable (TRUE vs FALSE).

The cleaned dataset has `r nrow(subway_df)` rows and `r ncol(subway_df)` columns. 
The dataset is not very tidy (e.g. route1-11 should be collapsed into one column).

* There are `r distinct(subway_df, line, station_name) %>% count()` distinct stations.
* `r filter(subway_df, ada == TRUE) %>% distinct(line, station_name) %>% count()` stations are ADA compliant.
* `r filter(subway_df, vending == "NO" & entry == "TRUE") %>% count() / filter(subway_df, vending == "NO") %>% count()` of station entrances / exits without vending allow entrance.


Reformat data to make route number and route name distinct variables.

```{r}
subway_tidy = 
  subway_df %>% 
  mutate_at(vars(route8:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name"
  ) %>% 
  drop_na(route_name)
```

* There are `r filter(subway_tidy, route_name == "A") %>% distinct(line, station_name) %>% count()` distinct stations that serve the A train.
* Among the stations that serve the A train, `r filter(subway_tidy, route_name == "A" & ada == TRUE) %>% distinct(line, station_name) %>% count()` are ADA compliant.


## Problem 3

Read and clean the pols-month dataset.

```{r}
pols_df = 
  read_csv("./data/pols-month.csv") %>%
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day")) %>%
  mutate(
    month = month.abb[as.factor(month)],
    president = case_when(prez_gop == 1 ~ "gop", prez_dem == 1 ~ "dem")
  ) %>% 
  select(-c(prez_dem, prez_gop, day))
```

Read and clean the snp dataset.

```{r}
snp_df = 
  read_csv("./data/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year")) %>%
  select(year, month, close)
```

Read and clean the unemployment dataset.

```{r}
unemployment_df = 
  read_csv("./data/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "Month",
    values_to = "unemp_pct"
  ) %>% 
  janitor::clean_names() %>% 
  mutate(year = as.character(year))
```

Join the three datasets.

```{r}
join_df = 
  left_join(pols_df, snp_df, by = c("year", "month")) %>% 
  left_join(unemployment_df, by = c("year", "month"))
```

The three datasets are from a post called Science Isn't Broken on the FiveThirtyEight website. Users can choose variables from these datasets to consider the association between political party and economic success.

* The _pol-month_ dataset contains `r nrow(pols_df)` rows and `r ncol(pols_df)` columns, 
the _snp_ dataset contains `r nrow(snp_df)` rows and `r ncol(snp_df)` columns, 
and the _unemployment_ dataset contains `r nrow(unemployment_df)` rows and `r ncol(unemployment_df)` columns.

* After breaking up the date variable into year and month variables and merging the three datasets by left join, I arrived the final dataset _join_df_, which contains `r nrow(join_df)` rows and `r ncol(join_df)` columns, and ranges from `r min(pull(join_df, year))` to `r max(pull(join_df, year))`. 

* Key variables: a group of variables regarding the number of national politicians who are democratic or republican at any given time (e.g. president), close (the closing values of the S&P stock index on the associated date), and unemp_pct (the percentage of unemployment).
